{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1: Set Covering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Input**: an integer k, a set P and S a subset of parts of P\n",
    "- **Problem**: There is a subset T of S, such that each number between 0 and k-1 appears in at least one list and the total numbers of elements in all T is minimum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to many research, set covering problem is the equivalent of a hitting graph problem, where the edges represents the elements of our goal and the nodes the set\n",
    "- It is a  graph problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- node: list L\n",
    "- edge: len(L)\n",
    "- goal: set(range(0:N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem(N, seed=None):\n",
    "    random.seed(seed)\n",
    "    return [\n",
    "        list(set(random.randint(0, N - 1) for n in range(random.randint(N // 5, N // 2))))\n",
    "        for n in range(random.randint(N, N * 5))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Github: Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NEW SOL: Found a solution in 13 steps; visited 5 nodes\n",
      "Greedy solution for N=5: w=5 (bloat=0%)\n",
      "NEW SOL: Found a solution in 14 steps; visited 7 nodes\n",
      "Greedy solution for N=10: w=13 (bloat=30%)\n",
      "NEW SOL: Found a solution in 14 steps; visited 12 nodes\n",
      "Greedy solution for N=20: w=46 (bloat=130%)\n",
      "NEW SOL: Found a solution in 23 steps; visited 19 nodes\n",
      "Greedy solution for N=100: w=332 (bloat=232%)\n",
      "NEW SOL: Found a solution in 28 steps; visited 24 nodes\n",
      "Greedy solution for N=500: w=2162 (bloat=332%)\n",
      "NEW SOL: Found a solution in 27 steps; visited 26 nodes\n",
      "Greedy solution for N=1000: w=4652 (bloat=365%)\n",
      "NEW SOL: Found a solution in 36 steps; visited 34 nodes\n",
      "Greedy solution for N=2000: w=12169 (bloat=508%)\n"
     ]
    }
   ],
   "source": [
    "def greedy(N):\n",
    "    goal = set(range(N))\n",
    "    covered = set()\n",
    "    solution = list()\n",
    "    all_lists = sorted(problem(N, seed=42), key=lambda l: len(l))\n",
    "    n=0\n",
    "    i=0\n",
    "    while goal != covered:\n",
    "        x = all_lists.pop(0)\n",
    "        i = i+1\n",
    "        if not set(x) < covered:\n",
    "            n = n+1\n",
    "            solution.append(x)\n",
    "            covered |= set(x)\n",
    "\n",
    "    logging.info(f\"NEW SOL: Found a solution in {i:,} steps; visited {n:,} nodes\")\n",
    "    logging.info(\n",
    "        f\"Greedy solution for N={N}: w={sum(len(_) for _ in solution)} (bloat={(sum(len(_) for _ in solution)-N)/N*100:.0f}%)\"\n",
    "    )\n",
    "    logging.debug(f\"{solution}\")\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "for N in [5, 10, 20, 100, 500, 1000,2000]:\n",
    "    greedy(N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    \"\"\"\n",
    "    The state at a moment of the search\n",
    "    defined by an array\n",
    "    \"\"\"    \n",
    "    def __init__(self, arr=[]):\n",
    "       self._array = arr.copy()\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(np.array(self._array).tobytes())\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return sum(len(_) for _ in self._array) ==  sum(len(_) for _ in other._array)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return sum(len(_) for _ in self._array) < sum(len(_) for _ in other._array)\n",
    "    def __str__(self):\n",
    "        return str(self) \n",
    "    \n",
    "    @property\n",
    "    def array(self):\n",
    "        return self._array\n",
    "    @array.setter\n",
    "    def array(self,value):\n",
    "        self._array = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_test(state,goal):\n",
    "    return state == goal\n",
    "def possible_actions(all_lists,covering):\n",
    "    return sorted([array for array in all_lists if len(set(array).difference(covering)) > 0], key=lambda l: len(l) )  \n",
    "def result(state, a):\n",
    "    array = state.array.copy()\n",
    "    array.append(a)\n",
    "    return(State(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gx_utils  import PriorityQueue\n",
    "\n",
    "def possible_actionsV2(all_lists,covering):\n",
    "    return [array for array in all_lists if len(set(array).difference(covering)) > 0]\n",
    "\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n",
    "def searchV2(N,initial_state,goal_test,parent_state,state_cost,priority_function,unit_cost):\n",
    "    \"\"\"\n",
    "    The search function\n",
    "    \"\"\"\n",
    "    state = initial_state\n",
    "    parent_state[state] = None\n",
    "    state_cost[state] = 0\n",
    "    solutions = []\n",
    "    covering = set()\n",
    "    step = 0\n",
    "    all_lists = sorted(problem(N,seed=42), key=lambda l: len(l))\n",
    "    while state is not None and  covering != goal_test:\n",
    "        frontier = PriorityQueue() # My frontier is 0 at each loop because he consider all the possible connected wiht the actual state. \n",
    "        for a in possible_actionsV2(all_lists,covering):\n",
    "                new_state = result(state, a)\n",
    "                cost = unit_cost(new_state) \n",
    "                if new_state not in state_cost and new_state not in frontier:\n",
    "                    parent_state[new_state] = state\n",
    "                    state_cost[new_state] = state_cost[state] + cost\n",
    "                    frontier.push(new_state, p=priority_function(new_state))\n",
    "                elif new_state in frontier and state_cost[new_state] > state_cost[state] + cost:\n",
    "                    old_cost = state_cost[new_state]\n",
    "                    parent_state[new_state] = state\n",
    "                    state_cost[new_state] = state_cost[state] + cost\n",
    "        if frontier:\n",
    "            state = frontier.pop()\n",
    "            step = step + 1\n",
    "            solutions.append(state.array)\n",
    "            covering |= set([el for a in state.array for el in a])\n",
    "        else:\n",
    "            state = None\n",
    "    path = list()\n",
    "    s = state\n",
    "    i = 0\n",
    "    while s:\n",
    "        path.append(s)\n",
    "        s = parent_state[s]\n",
    "    logging.info(f\"NEW SOL: Found a solution in {step} nodes; \")\n",
    "    return state.array,list(reversed(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gready Best-First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp/ipykernel_26064/2412138750.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return hash(np.array(self._array).tobytes())\n",
      "NEW SOL: Found a solution in 3 nodes; \n",
      "gready_best_first first solution for N=5: w=5 (bloat=0%)\n",
      "NEW SOL: Found a solution in 3 nodes; \n",
      "gready_best_first first solution for N=10: w=10 (bloat=0%)\n",
      "NEW SOL: Found a solution in 4 nodes; \n",
      "gready_best_first first solution for N=20: w=28 (bloat=40%)\n",
      "NEW SOL: Found a solution in 5 nodes; \n",
      "gready_best_first first solution for N=100: w=192 (bloat=92%)\n",
      "NEW SOL: Found a solution in 7 nodes; \n",
      "gready_best_first first solution for N=500: w=1320 (bloat=164%)\n",
      "NEW SOL: Found a solution in 8 nodes; \n",
      "gready_best_first first solution for N=1000: w=2893 (bloat=189%)\n"
     ]
    }
   ],
   "source": [
    "def greedy_first(N):\n",
    "    INITIAL_STATE = State()\n",
    "    parent_state = dict()\n",
    "    state_cost = dict()\n",
    "    covering = set()\n",
    "    goal  =  set(range(N))\n",
    "    def h(state):\n",
    "        return len(goal.difference(set([el for a in state.array for el in a])))\n",
    "\n",
    "    final = searchV2(\n",
    "        N,\n",
    "        INITIAL_STATE,\n",
    "        goal_test=goal,\n",
    "        parent_state=parent_state,\n",
    "        state_cost=state_cost,\n",
    "        priority_function=lambda s: h(s) ,\n",
    "        unit_cost=lambda a: sum(len(_) for _ in a.array)\n",
    "    )\n",
    "    logging.info(\n",
    "            f\"gready_best_first first solution for N={N}: w={sum(len(_) for _  in final[0])} (bloat={(sum(len(_) for _ in final[0])-N)/N*100:.0f}%)\"\n",
    "        )\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "for N in [5,10,20,100,500,1000]:\n",
    "    greedy_first(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp/ipykernel_26064/2412138750.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return hash(np.array(self._array).tobytes())\n",
      "NEW SOL: Found a solution in 5 nodes; \n",
      "A* first solution for N=5: w=5 (bloat=0%)\n",
      "NEW SOL: Found a solution in 6 nodes; \n",
      "A* first solution for N=10: w=11 (bloat=10%)\n",
      "NEW SOL: Found a solution in 7 nodes; \n",
      "A* first solution for N=20: w=28 (bloat=40%)\n",
      "NEW SOL: Found a solution in 13 nodes; \n",
      "A* first solution for N=100: w=230 (bloat=130%)\n",
      "NEW SOL: Found a solution in 20 nodes; \n",
      "A* first solution for N=500: w=1828 (bloat=266%)\n",
      "NEW SOL: Found a solution in 23 nodes; \n",
      "A* first solution for N=1000: w=4130 (bloat=313%)\n"
     ]
    }
   ],
   "source": [
    "def a_star(N):\n",
    "    INITIAL_STATE = State()\n",
    "    parent_state = dict()\n",
    "    state_cost = dict()\n",
    "    covering = set()\n",
    "    goal  =  set(range(N))\n",
    "    def h(state):\n",
    "        return len(goal.difference(set([el for a in state.array for el in a])))\n",
    "\n",
    "    final = searchV2(\n",
    "        N,\n",
    "        INITIAL_STATE,\n",
    "        goal_test=goal,\n",
    "        parent_state=parent_state,\n",
    "        state_cost=state_cost,\n",
    "        priority_function=lambda s: h(s) + state_cost[s] ,\n",
    "        unit_cost=lambda a: sum(len(_) for _ in a.array)\n",
    "    )\n",
    "    logging.info(\n",
    "            f\"A* first solution for N={N}: w={sum(len(_) for _  in final[0])} (bloat={(sum(len(_) for _ in final[0])-N)/N*100:.0f}%)\"\n",
    "        )\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "for N in [5,10,20,100,500,1000]:\n",
    "    a_star(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breath First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp/ipykernel_26064/2412138750.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return hash(np.array(self._array).tobytes())\n",
      "NEW SOL: Found a solution in 6 steps; visited 40 nodes\n",
      "breath_first first solution for N=5: w=5 (bloat=0%)\n",
      "NEW SOL: Found a solution in 8 steps; visited 267 nodes\n",
      "breath_first first solution for N=10: w=13 (bloat=30%)\n",
      "NEW SOL: Found a solution in 13 steps; visited 304 nodes\n",
      "breath_first first solution for N=20: w=46 (bloat=130%)\n",
      "NEW SOL: Found a solution in 20 steps; visited 7,270 nodes\n",
      "breath_first first solution for N=100: w=332 (bloat=232%)\n",
      "NEW SOL: Found a solution in 25 steps; visited 40,366 nodes\n",
      "breath_first first solution for N=500: w=2162 (bloat=332%)\n",
      "NEW SOL: Found a solution in 27 steps; visited 87,907 nodes\n",
      "breath_first first solution for N=1000: w=4652 (bloat=365%)\n"
     ]
    }
   ],
   "source": [
    "def breath_first(N):\n",
    "    INITIAL_STATE = State()\n",
    "    parent_state = dict()\n",
    "    state_cost = dict()\n",
    "    covering = set()\n",
    "    goal  =  set(range(N))\n",
    "\n",
    "\n",
    "    final = searchV2(\n",
    "        N,\n",
    "        INITIAL_STATE,\n",
    "        goal_test=goal,\n",
    "        parent_state=parent_state,\n",
    "        state_cost=state_cost,\n",
    "        priority_function=lambda s: len(state_cost) ,\n",
    "        unit_cost=lambda a: 1\n",
    "    )\n",
    "    logging.info(\n",
    "            f\"breath_first first solution for N={N}: w={sum(len(_) for _  in final[0])} (bloat={(sum(len(_) for _ in final[0])-N)/N*100:.0f}%)\"\n",
    "        )\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "for N in [5,10,20,100,500,1000]:\n",
    "    breath_first(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp/ipykernel_26064/2412138750.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return hash(np.array(self._array).tobytes())\n",
      "NEW SOL: Found a solution in 5 steps; visited 47 nodes\n",
      "breath_first first solution for N=5: w=8 (bloat=60%)\n",
      "NEW SOL: Found a solution in 5 steps; visited 119 nodes\n",
      "breath_first first solution for N=10: w=19 (bloat=90%)\n",
      "NEW SOL: Found a solution in 8 steps; visited 159 nodes\n",
      "breath_first first solution for N=20: w=57 (bloat=185%)\n",
      "NEW SOL: Found a solution in 10 steps; visited 3,123 nodes\n",
      "breath_first first solution for N=100: w=379 (bloat=279%)\n",
      "NEW SOL: Found a solution in 11 steps; visited 16,751 nodes\n",
      "breath_first first solution for N=500: w=2044 (bloat=309%)\n",
      "NEW SOL: Found a solution in 14 steps; visited 40,987 nodes\n",
      "breath_first first solution for N=1000: w=5242 (bloat=424%)\n"
     ]
    }
   ],
   "source": [
    "def depth_first(N):\n",
    "    INITIAL_STATE = State()\n",
    "    parent_state = dict()\n",
    "    state_cost = dict()\n",
    "    covering = set()\n",
    "    goal  =  set(range(N))\n",
    "\n",
    "\n",
    "    final = searchV2(\n",
    "        N,\n",
    "        INITIAL_STATE,\n",
    "        goal_test=goal,\n",
    "        parent_state=parent_state,\n",
    "        state_cost=state_cost,\n",
    "        priority_function=lambda s: -len(state_cost) ,\n",
    "        unit_cost=lambda a: 1\n",
    "    )\n",
    "    logging.info(\n",
    "            f\"breath_first first solution for N={N}: w={sum(len(_) for _  in final[0])} (bloat={(sum(len(_) for _ in final[0])-N)/N*100:.0f}%)\"\n",
    "        )\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "for N in [5,10,20,100,500,1000]:\n",
    "    depth_first(N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca9c90c9b299e3c35d28bc96236d8f2c0bd3d51256cb5ad616950692d4a1a879"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
